---
layout: default
title: AI design & ethics
permalink: /AI/
theme: jekyll-theme-dinky
---

### AI Design & Ethics


[Design for AI deck](/assets/AI.pptx)

[IBM AI design presentation recording](/assets/AI.mp4)


Everyday ethics for AI provides discussion points concerning:
- specific virtues that AI systems should possess;
- guidance for designers and developers training and building AI.

**Focal areas include:**
1. Accountability
2. Value Alignment
3. Explainability
4. Fairness
5. User Data Rights

**Accountability**

- AI designers  and developers are responsible  for considering  AI design, development, decision  processes,  and outcomes.
- Human judgment plays a role throughout a seemingly objective  system of logical decisions.  It is humans who write  algorithms,  who define success or failure,  who make decisions  about the uses of systems and who may be affected by a system’s outcomes.
- Every person involved in  the creation  of AI at any step is  accountable for considering the system’s impact in the world, as are the companies invested in its  development.

**Value Alignment**

- AI should be designed  to align with the norms and values of your user group  in mind.
- AI works alongside  diverse,  human interests.  People make decisions  based  on any number of contextual factors,  including  their experiences,  memories, upbringing,  and cultural norms. 
- Today’s AI systems do not have these types of experiences to draw upon, so it is the job  of designers  and developers to collaborate with each other in  order to ensure consideration  of existing  values. Care is  required  to ensure sensitivity to a wide range of cultural norms and values. 

**Explainability**
- AI should be designed for humans to easily perceive, detect,  and understand  its decision process.
- In general, we don’t blindly trust those who can’t explain their reasoning. The same goes for AI, perhaps even more so.Your users should always be aware that they are interacting with an AI. Good design does not sacrifice transparency in creating a seamless experience. Imperceptible AI is not ethical AI.

**Fairness**
- AI must be designed  to minimize  bias  and promote inclusive representation.
- AI provides deeper insight  into our personal lives when interacting  with our sensitive  data.  As humans are inherently vulnerable to biases,  and are responsible  for building  AI,  there are chances for human bias  to be embedded in the systems we create. It is the role of a responsible  team to minimize  algorithmic  bias  through ongoing research and data  collection which is  representative  of a diverse population

**User Rights**
- AI must be designed to protect user data and preserve the user’s power over access and uses. 
- Pew Research recently found that being in control of our own information is “very important” to 74% of Americans. 
- The European Commission found that 71% of EU citizens find it unacceptable for companies to share information about them without their permission. 

### Real world examples

1. **Use AI for Grading** - [One real world example](https://hbr.org/2020/08/what-happens-when-ai-is-used-to-set-grades)
2. **Cheating AI grading systems** - [Want perfect scores?](https://www.theverge.com/2020/9/2/21419012/edgenuity-online-class-ai-grading-keyword-mashing-students-school-cheating-algorithm-glitch)
3. **It's all about Algorithms** - [Flawed Algorithms grading Essays](https://www.vice.com/en/article/pa7dj9/flawed-algorithms-are-grading-millions-of-students-essays)

## IBM Developer resources

1. [**AI Fairness 360**](https://aif360.mybluemix.net/)
This extensible open source toolkit can help you examine, report, and mitigate discrimination and bias in machine learning models throughout the AI application lifecycle. We invite you to use and improve it.

2. [**AI Explainability 360**](https://aix360.mybluemix.net/)
This extensible open source toolkit can help you comprehend how machine learning models predict labels by various means throughout the AI application lifecycle. We invite you to use it and improve it.

